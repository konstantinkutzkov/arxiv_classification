{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import * \n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score as acc, f1_score, roc_auc_score as auc\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/home/koki/Desktop/Data/NLP/arxiv/archive/arxiv-metadata-oai-snapshot.json'\n",
    "            #'/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json'\n",
    "labelmap = {}\n",
    "sample_rate = 5\n",
    "abstracts_train, labels_train, labelmap = get_data_and_labels(\n",
    "                    datapath=datapath,\n",
    "                    year=2021, \n",
    "                    month_start=1,\n",
    "                    month_end=12,\n",
    "                    labelmap=labelmap,\n",
    "                    update_map=True,\n",
    "                    sample_rate=sample_rate\n",
    "                    )\n",
    "\n",
    "abstracts_val, labels_val, _ = get_data_and_labels(\n",
    "                    datapath=datapath,\n",
    "                    year=2022, \n",
    "                    month_start=1,\n",
    "                    month_end=6,\n",
    "                    labelmap=labelmap,\n",
    "                    update_map=False,\n",
    "                    sample_rate=sample_rate\n",
    "                    )\n",
    "\n",
    "abstracts_test, labels_test, _ = get_data_and_labels(\n",
    "                    datapath=datapath,\n",
    "                    year=2022, \n",
    "                    month_start=7,\n",
    "                    month_end=12,\n",
    "                    labelmap=labelmap,\n",
    "                    update_map=False,\n",
    "                    sample_rate=sample_rate\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b44e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, tokenizer, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "stopword_list=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "toktok_tokenizer=ToktokTokenizer()\n",
    "def clean(abstracts, tokenizer=toktok_tokenizer):\n",
    "    clean_abstracts = [denoise_text(abstract) for abstract in abstracts] \n",
    "    clean_abstracts = [remove_special_characters(abstract) for abstract in clean_abstracts]  \n",
    "    clean_abstracts = [remove_stopwords(abstract, tokenizer, is_lower_case=True) for abstract in \\\n",
    "                       clean_abstracts]  \n",
    "    return clean_abstracts\n",
    "clean_train = clean(abstracts_train)\n",
    "clean_val = clean(abstracts_val)\n",
    "clean_test = clean(abstracts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(min_df=0.01,max_df=0.5,binary=False,ngram_range=(1,1))\n",
    "cv_train = cv.fit_transform(clean_train)\n",
    "cv_val = cv.transform(clean_val)\n",
    "cv_test = cv.transform(clean_test)\n",
    "\n",
    "assert cv_train.shape[1] == cv_val.shape[1]\n",
    "assert cv_train.shape[1] == cv_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=cv_train.toarray(),columns = cv.get_feature_names_out())\n",
    "X_val = pd.DataFrame(data=cv_val.toarray(),columns = cv.get_feature_names_out())\n",
    "X_test = pd.DataFrame(data=cv_test.toarray(),columns = cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, labelmap):  \n",
    "    encoded = np.zeros((len(y), len(labelmap))) #len(np.unique(y))))\n",
    "    for i, label_i in enumerate(y):\n",
    "        for lb_j in label_i:\n",
    "            encoded[i, lb_j] = 1       \n",
    "    return encoded\n",
    "\n",
    "y_train = one_hot(labels_train, labelmap)\n",
    "y_val = one_hot(labels_val, labelmap)\n",
    "y_test = one_hot(labels_test, labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b429cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ce9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0\n",
    "best_model = None\n",
    "for depth in range(3, 5):\n",
    "    print('depth', depth)\n",
    "    model = tree.DecisionTreeClassifier(max_depth=depth) \n",
    "    model = OneVsRestClassifier(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_prob = model.predict_proba(X_val) \n",
    "    current_auc = auc(y_val, y_pred_prob)\n",
    "    print('AUC', current_auc)\n",
    "    if current_auc > best_auc:\n",
    "        best_auc = current_auc\n",
    "        best_model = model\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_prob = best_model.predict_proba(X_test)\n",
    "\n",
    "auc_micro, auc_macro, f1_micro, f1_macro = \\\n",
    "                auc(y_test, y_pred_prob, average='micro'), auc(y_test, y_pred_prob, average='macro'),\\\n",
    "                f1_score(y_test, y_pred, average='micro'), f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('micro-AUC: {}, macro-AUC: {}, micro-F1: {}, macro-F1: {}'.format(np.round(auc_micro, 3),\\\n",
    "                                    np.round(auc_macro, 3), np.round(micro, 3), np.round(macro, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dec821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
